{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a47414",
   "metadata": {},
   "source": [
    "# Data Exports for PowerBI Dashboard\n",
    "This notebook prepares and exports the final dataset with model predictions for PowerBI visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c811dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and model...\n",
      "Data loaded: 49358 rows\n",
      "\n",
      "Categorical columns encoded:\n",
      "- value_segment: [3 1 2 0]\n",
      "- recency_segment: [0 2 1 3]\n",
      "- risk_segment: [0 2 1 3 4]\n",
      "Data loaded: 49358 rows\n",
      "\n",
      "Categorical columns encoded:\n",
      "- value_segment: [3 1 2 0]\n",
      "- recency_segment: [0 2 1 3]\n",
      "- risk_segment: [0 2 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Loading data and model...\")\n",
    "\n",
    "# Load the preprocessed data\n",
    "df = pd.read_csv('../data/processed/preprocessed_churn_data.csv')\n",
    "\n",
    "# Load the model and metadata\n",
    "with open('../models/churn_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "with open('../models/model_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "    \n",
    "# Load the encoders\n",
    "with open('../models/encoders.pkl', 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "\n",
    "print(f\"Data loaded: {len(df)} rows\")\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = ['value_segment', 'recency_segment', 'risk_segment']\n",
    "\n",
    "# Create copy of original categorical values before encoding\n",
    "original_cat_values = {}\n",
    "for col in categorical_columns:\n",
    "    original_cat_values[col] = df[col].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "for col in categorical_columns:\n",
    "    if col in encoders:\n",
    "        df[col] = encoders[col].transform(df[col])\n",
    "    else:\n",
    "        # If encoder not found, create new one\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "\n",
    "print(\"\\nCategorical columns encoded:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"- {col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3167fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding model predictions...\n",
      "\n",
      "New columns added:\n",
      "- model_churn_probability: Probability of churning (0-1)\n",
      "- model_prediction: Binary prediction (0/1)\n",
      "- prediction_correct: Whether prediction matches actual class\n",
      "- false_negative: Missed actual churners\n",
      "- false_positive: False churn predictions\n",
      "- model_confidence: Confidence score (0-1)\n",
      "\n",
      "Sample predictions:\n",
      "  value_segment risk_segment  model_churn_probability  model_prediction  \\\n",
      "0   No Purchase         High                 0.690216                 1   \n",
      "1   No Purchase         High                 0.736367                 1   \n",
      "2   No Purchase       Medium                 0.705747                 1   \n",
      "3   No Purchase          Low                 0.584194                 1   \n",
      "4   No Purchase       Medium                 0.558646                 1   \n",
      "\n",
      "   model_confidence  \n",
      "0          0.380431  \n",
      "1          0.472735  \n",
      "2          0.411494  \n",
      "3          0.168388  \n",
      "4          0.117292  \n"
     ]
    }
   ],
   "source": [
    "# Prepare features for prediction\n",
    "feature_cols = metadata['feature_columns'] if 'feature_columns' in metadata else [\n",
    "    col for col in df.columns if col not in ['target_class', 'visitorid']\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "print(\"Adding model predictions...\")\n",
    "\n",
    "# 1. Add model predictions\n",
    "df['model_churn_probability'] = model.predict_proba(X)[:, 1]\n",
    "df['model_prediction'] = model.predict(X)  # Binary 0/1 prediction\n",
    "\n",
    "# 2. Add model performance analysis\n",
    "df['prediction_correct'] = (df['model_prediction'] == df['target_class'])\n",
    "df['false_negative'] = (df['model_prediction'] == 0) & (df['target_class'] == 1)\n",
    "df['false_positive'] = (df['model_prediction'] == 1) & (df['target_class'] == 0)\n",
    "\n",
    "# 3. Add model confidence\n",
    "df['model_confidence'] = abs(df['model_churn_probability'] - 0.5) * 2\n",
    "\n",
    "# Restore original categorical values\n",
    "for col, original_values in original_cat_values.items():\n",
    "    df[col] = original_values\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "print(\"- model_churn_probability: Probability of churning (0-1)\")\n",
    "print(\"- model_prediction: Binary prediction (0/1)\")\n",
    "print(\"- prediction_correct: Whether prediction matches actual class\")\n",
    "print(\"- false_negative: Missed actual churners\")\n",
    "print(\"- false_positive: False churn predictions\")\n",
    "print(\"- model_confidence: Confidence score (0-1)\")\n",
    "\n",
    "# Show sample of predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "sample_cols = ['value_segment', 'risk_segment', 'model_churn_probability', 'model_prediction', 'model_confidence']\n",
    "print(df[sample_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d7d6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification of new columns:\n",
      "\n",
      "Model Predictions Summary:\n",
      "       model_churn_probability  model_prediction\n",
      "count             49358.000000      49358.000000\n",
      "mean                  0.587636          0.685279\n",
      "std                   0.197596          0.464409\n",
      "min                   0.008969          0.000000\n",
      "25%                   0.455756          0.000000\n",
      "50%                   0.610614          1.000000\n",
      "75%                   0.746175          1.000000\n",
      "max                   0.943603          1.000000\n",
      "\n",
      "Prediction Performance:\n",
      "Correct predictions: 72.7%\n",
      "False negatives: 11690 (23.7%)\n",
      "False positives: 1803 (3.7%)\n",
      "\n",
      "Model Confidence:\n",
      "count    49358.000000\n",
      "mean         0.366709\n",
      "std          0.228952\n",
      "min          0.000008\n",
      "25%          0.165536\n",
      "50%          0.354587\n",
      "75%          0.548411\n",
      "max          0.982062\n",
      "Name: model_confidence, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify the new columns\n",
    "print(\"Verification of new columns:\")\n",
    "print(\"\\nModel Predictions Summary:\")\n",
    "print(df[['model_churn_probability', 'model_prediction']].describe())\n",
    "\n",
    "print(\"\\nPrediction Performance:\")\n",
    "print(f\"Correct predictions: {df['prediction_correct'].mean():.1%}\")\n",
    "print(f\"False negatives: {df['false_negative'].sum()} ({df['false_negative'].mean():.1%})\")\n",
    "print(f\"False positives: {df['false_positive'].sum()} ({df['false_positive'].mean():.1%})\")\n",
    "\n",
    "print(\"\\nModel Confidence:\")\n",
    "print(df['model_confidence'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31682eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced dataset saved to: ../data/exports/churn_predictions_powerbi.csv\n",
      "Total columns: 75\n",
      "Total rows: 49358\n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced dataset\n",
    "output_path = '../data/exports/churn_predictions_powerbi.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nEnhanced dataset saved to: {output_path}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
